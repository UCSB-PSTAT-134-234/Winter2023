{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9e25c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "running-a-cell",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Part 1: Using Jupyter Notebook\n",
    "\n",
    "### Running Cells and Displaying Output\n",
    "\n",
    "Run the following cell.  If you are unfamiliar with Jupyter Notebooks, skim [this tutorial](http://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb) or selecting **Help --> JupyterLab Reference** in the menu bar above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T23:27:51.557447Z",
     "start_time": "2019-01-18T23:27:51.552368Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "hello-world",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Jupyter notebooks, all print statements are displayed below the cell. Furthermore, the output of the last line is displayed following the cell upon execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T23:27:51.593806Z",
     "start_time": "2019-01-18T23:27:51.559501Z"
    }
   },
   "outputs": [],
   "source": [
    "\"Will this line be displayed?\"\n",
    "\n",
    "print(\"Hello\" + \",\", \"world!\")\n",
    "\n",
    "5 + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Documentation\n",
    "\n",
    "To output the documentation for a function, use the `help` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T23:27:51.618364Z",
     "start_time": "2019-01-18T23:27:51.596329Z"
    }
   },
   "outputs": [],
   "source": [
    "help(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use Jupyter to view function documentation inside your notebook. The function must already be defined in the kernel for this to work.\n",
    "\n",
    "Below, click your mouse anywhere on `print()` and use `Shift` + `Tab` to view the function's documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T23:27:51.642969Z",
     "start_time": "2019-01-18T23:27:51.620450Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Welcome to PSTAT 134.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Magic Commands\n",
    "\n",
    "In PSTAT 134, we will be using common Python libraries to help us process data. By convention, we import all libraries at the very top of the notebook. There are also a set of standard aliases that are used to shorten the library names. Below are some of the libraries that you may encounter throughout the course, along with their respective aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T23:27:53.746048Z",
     "start_time": "2019-01-18T23:27:51.644613Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful magic command is `%%time`, which times the execution of that cell. You can use this by writing it as the first line of a cell. (Note that `%%` is used for *cell magic commands* that apply to the entire cell, whereas `%` is used for *line magic commands* that only apply to a single line.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T23:27:53.755085Z",
     "start_time": "2019-01-18T23:27:53.749765Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lst = []\n",
    "for i in range(100):\n",
    "    lst.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "shortcuts",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Keyboard Shortcuts\n",
    "\n",
    "Even if you are familiar with Jupyter, we strongly encourage you to become proficient with keyboard shortcuts (this will save you time in the future). To learn about keyboard shortcuts, go to **Help --> Keyboard Shortcuts** in the menu above. \n",
    "\n",
    "Here are a few that we like:\n",
    "1. `Ctrl` + `Return` : *Evaluate the current cell*\n",
    "1. `Shift` + `Return`: *Evaluate the current cell and move to the next*\n",
    "1. `ESC` : *command mode* (may need to press before using any of the commands below)\n",
    "1. `a` : *create a cell above*\n",
    "1. `b` : *create a cell below*\n",
    "1. `dd` : *delete a cell*\n",
    "1. `z` : *undo the last cell operation*\n",
    "1. `m` : *convert a cell to markdown*\n",
    "1. `y` : *convert a cell to code*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Lab\n",
    "\n",
    "JupyterLab is the next generation Jupyter environment that includes more than Jupyter Notebook.\n",
    "![JupyterLab](images/jupyterlab.png)\n",
    "\n",
    "To use Jupyter Lab, visit http://pstat-134-234.lsit.ucsb.edu."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "---\n",
    "# Part 2: Jupyter notebook labs and assignments\n",
    "\n",
    "**Note: this lab notebook will not count toward your grade, but it is designed to give you a full understanding of how the graders work for this class**\n",
    "\n",
    "In this class, some labs and assignments based on Jupyter notebooks will be graded by Gradescope autograder. The grading is done by \"tests\" some of which are visible and others are hidden.\n",
    "\n",
    "The remainder of this notebook illustrates how the grading works, and, during the process, explain various components that help you understand and work on your labs and assignments easier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "#### Instructions\n",
    "\n",
    "The software being used is called [**otter grader**](https://otter-grader.readthedocs.io). Here are the basics:\n",
    "\n",
    "* **You must NOT change the notebook file name.**  \n",
    "    Notice the first cell has the name of this notebook `lab1.ipynb`. Changing the name of this Jupyter notebook file will cause problems.\n",
    "\n",
    "* **Each question is marked by a code chunk: e.g.**  \n",
    "    ```\n",
    "    <!--\n",
    "    BEGIN QUESTION\n",
    "    name: q1a\n",
    "    -->\n",
    "    ```  \n",
    "\n",
    "* **Each question has a response cell _directly_ below it.**  \n",
    "    This is where you answer the question. If you have extra content in this cell, that's fine.\n",
    "    \n",
    "* **If a question has tests, grading cell follows the response cell.**  \n",
    "    Most response cells are followed by a test cell that runs automated tests to check your work: e.g.  \n",
    "    ```\n",
    "    grader.check(\"q1a\");\n",
    "    ```\n",
    "    Test results are meant to give you some useful feedback, but it's your responsibility to answer the question. \n",
    "    \n",
    "* **Keep Question-Response-Grading cell intact**  \n",
    "    Please don't delete questions, response cells, or test cells. You won't get credit for your work if you do.\n",
    "\n",
    "* **Important: test cells don't always confirm that your response is correct.**  \n",
    "    There may be other tests that we run when scoring your notebooks. We **strongly recommend** that you check your solutions yourself rather than just relying on the test cells.\n",
    "    \n",
    "* **Double check your submission**  \n",
    "    Make sure the correct file is submitted\n",
    "    \n",
    "Please refer to this documentation for how you can use it more effectively: https://otter-grader.readthedocs.io/en/latest/otter_check.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample question\n",
    "\n",
    "Suppose the question to be graded is \n",
    "> What is the smallest prime number? Assign it to variable `x`.\n",
    "\n",
    "The correct answer would be `x = 2`.\n",
    "\n",
    "## Tests\n",
    "\n",
    "A test in our Jupyter notebook grading context is a piece of code and the expected result of that code. For the sample question, some examples of tests could be, \n",
    "\n",
    "1. Test code: `isinstance(x, int)`  \n",
    "    Expected result: `True`\n",
    "2. Test code: `0 < x < 100`  \n",
    "    Expected result: `True`\n",
    "3. Test code: `print(x)`  \n",
    "    Expected result: `2`\n",
    "    \n",
    "In your notebook, tests such as these are executed to evaluate your grade. Below, the outputs in your notebook and Gradescope are explained in detail."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Example Question 1\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "manual: false\n",
    "points: 3\n",
    "-->\n",
    "\n",
    "What is the smallest prime number? Assign it to variable `x`.\n",
    "\n",
    "The correct answer is, \n",
    "```python\n",
    "x = 2\n",
    "```\n",
    "\n",
    "Suppose following are the three tests\n",
    "\n",
    "| Test code  | Expected result |\n",
    "| -------    | -------         |\n",
    "| `isinstance(x, int)` | `True`          |\n",
    "| `0 < x < 100` | `True`          |\n",
    "| `print(x)` | `2`          |\n",
    "\n",
    "If the student responds correctly as below, all tests would pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2 # student response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d2d19",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Example Question 2\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "manual: false\n",
    "points: 3\n",
    "-->\n",
    "\n",
    "We will create a similar question, but student will respond differently to this question.\n",
    "\n",
    "What is the smallest prime number? Assign it to variable `y`.\n",
    "\n",
    "The correct answer is, \n",
    "```python\n",
    "y = 2\n",
    "```\n",
    "\n",
    "Suppose following are the three tests\n",
    "\n",
    "| Test code  | Expected result |\n",
    "| -------    | -------         |\n",
    "| `isinstance(y, int)` | `True`          |\n",
    "| `0 < y < 100` | `True`          |\n",
    "| `print(y)` | `2`          |\n",
    "\n",
    "If the response is something like `y=2.3`, some one test would pass although the response is technically wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2.3 # student response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696cd57e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "3## Example Question 3\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "manual: false\n",
    "points: 3\n",
    "-->\n",
    "\n",
    "We will create a yet another similar question, but one of the tests will be hidden from you.\n",
    "\n",
    "What is the smallest prime number? Assign it to variable `z`.\n",
    "\n",
    "The correct answer is, \n",
    "```python\n",
    "z = 2\n",
    "```\n",
    "\n",
    "Suppose following are the three tests\n",
    "\n",
    "| Test code  | Expected result |\n",
    "| -------    | -------         |\n",
    "| `isinstance(z, int)` | `True`          |\n",
    "| `0 < z < 100` | `True`          |\n",
    "| `print(z)` | `2`          |\n",
    "\n",
    "In particular, the third test is hidden from you. If the response is `z=3`, the first two tests would be shown as passing; however, the result of the third test will not be visible when you are working on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 3 # student response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f92cad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More about tests and expected output\n",
    "\n",
    "Look in the directory named `tests`. This directory contains the visible tests.\n",
    "\n",
    "For Question 3 the corresponding test file is `tests/q3.py`. The content is \n",
    "\n",
    "```python\n",
    "test = {   'name': 'q3',\n",
    "    'points': 3,\n",
    "    'suites': [   {   'cases': [{'code': '>>> isinstance(z, int)\\nTrue', 'hidden': False, 'locked': False}, {'code': '>>> 0 < z < 100\\nTrue', 'hidden': False, 'locked': False}],\n",
    "                      'scored': True,\n",
    "                      'setup': '',\n",
    "                      'teardown': '',\n",
    "                      'type': 'doctest'}]}\n",
    "\n",
    "```\n",
    "\n",
    "You can infer that the total number of points for this question is 3, and there are two visible tests. For each test, the test code and expected result are shown as the dictionary value for key, `'code'`. For instance, the two tests/expected results are,\n",
    "\n",
    "1. `isinstance(z, int)\\nTrue`  \n",
    "    test code: `isinstance(z, int)`  \n",
    "    expected result: `True`\n",
    "2. `0 < z < 100\\nTrue`\n",
    "    test code: `0 < z < 100`  \n",
    "    expected result: `True`\n",
    "\n",
    "**A word of caution**: the tests being correct is a necessary condition but not sufficient condition for the correctness of your code. In other words, you may be passing all the (visible) tests; however, your response could still be incorrect. In [Example Question 3](#example-question-3), the test of  has a hidden test that checks if the value of `print(z)` is `2`.  You will not see any hidden tests while you are working on the assignment; however, the result of the hidden tests are revealed when final grades are released on Gradescope."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Example Question 4\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "manual: true\n",
    "points: 5\n",
    "-->\n",
    "\n",
    "Here is a question to be graded manually: create a matplotlib visualization of a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = {'a': np.arange(50),\n",
    "        'c': np.random.randint(0, 50, 50),\n",
    "        'd': np.random.randn(50)}\n",
    "data['b'] = data['a'] + 10 * np.random.randn(50)\n",
    "data['d'] = np.abs(data['d']) * 100\n",
    "\n",
    "plt.scatter('a', 'b', c='c', s='d', data=data)\n",
    "plt.xlabel('entry a')\n",
    "plt.ylabel('entry b')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Preparing Gradescope Submission Package\n",
    "\n",
    "The function `grader.export()` compiles a pdf file with your responses to the manually graded questions. When you are ready to create your submission package, follow these steps:\n",
    "\n",
    "1. Go to Kernel > Restart Kernel and Run All Cells...\n",
    "2. Save your notebook\n",
    "3. Again! Go to Kernel > Restart Kernel and Run All Cells...\n",
    "\n",
    "You must open the pdf and make sure all your responses show up correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15647a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5dcac4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1cdfdc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "The link to download the zip file will not work in Jupyter Lab. Download the zip file from the left-hand side file explorer panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66c4ca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee844b7",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
