{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7859abd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Lab 5: Image Compression and Matrix Factorization\n",
    "\n",
    "Matrix factorization is a way to find a set of basis vectors that describe a given dataset. Depending on the factorization used, the set of bases are different.\n",
    "\n",
    "In this notebook, we use singular value decomposition (SVD) and nonnegative matrix factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faces dataset\n",
    "\n",
    "We use \"[labeled faces in the wild](http://vis-www.cs.umass.edu/lfw/)\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "img_count, img_height, img_width = lfw_people.images.shape\n",
    "print('number of faces in dataset:', img_count)\n",
    "print('image width in pixels     :', img_width)\n",
    "print('image height in pixels    :', img_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each face is vectorized into a row in data matrix `X`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 1a: Data transformation\n",
    "\n",
    "Inspecting `lfw_people.images.shape` shows images are stored as a 3-dimensional array of size (1288, 50, 37). Use `numpy.ndarray.reshape()` to tranform matrix `lfw_people.images` to a 2-dimensional array of size `image_count` by `image_width` * `image_height` with name `X`. Take first image, `X[0]`, and `numpy.ndarray.reshape()` it back to a 2-dimensional array of size `image_width` * `image_height` with name `X0_img`. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = ...\n",
    "X0_img = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54283de4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went correctly, you should see a gray scale image below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# each row of X is a vectorized image\n",
    "plt.imshow(X0_img, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 1b: Visualization\n",
    "\n",
    "To make plotting easier, create a plotting function.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "manual: true\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_img(img_vector, h=img_height, w=img_width):\n",
    "    \"\"\"\n",
    "    1. takes img_vector,\n",
    "    2. reshapes into right dimensions,\n",
    "    3. draws the resulting image\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow( (...).reshape(...), cmap=plt.cm.gray)\n",
    "    \n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "_Cell Intentionally Blank_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check draw_img function\n",
    "draw_img(X[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 1c: Standardization\n",
    "\n",
    "Since SVD looks for singular values (related to eigenvalues) and eigenvectors of `X`, center each column (pixel) of `X` so that mean of each column is zero. Otherwise the result can be strange. This is a detail that is not critical for understanding the conceptual aspect of SVD. The variance of each pixel can be left alone. Use [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to standardize `X` (hint: use `.fit_transform`).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_std=False)\n",
    "Xstd = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca42ed",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean centered images look unnatural, but all the pertinent data is retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization transforms image data\n",
    "draw_img(Xstd[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Transformation\n",
    "\n",
    "We can recover the original data by putting the means back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse tranformation recovers original image units\n",
    "Xorig = scaler.inverse_transform(Xstd)\n",
    "draw_img(Xorig[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2a: Singular Value Decomposition (SVD)\n",
    "\n",
    "Numpy package has SVD decomposition function [`numpy.linalg.svd`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html). Decompose `Xstd` into `U`, `S`, `VT`, i.e., $X_{std} = U S V^T$.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import svd\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d016a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2b: Matrix Factors from SVD\n",
    "\n",
    "Since `S` is a diagonal matrix, multiplying `U` by `S` is like scaling each column of `U` by the corresponding diagonal entry. Check that we can recover the original data from the matrix factors by inverse transforming the resulting `Xhat`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "US = U*S\n",
    "\n",
    "# reconstruct standardized images from matrix factors\n",
    "Xhat = ...\n",
    "\n",
    "# inverse transform Xhat to remove standardization\n",
    "Xhat_orig = ...\n",
    "\n",
    "draw_img(Xhat_orig[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07717120",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction\n",
    "\n",
    "We can describe each face using smaller portions of matrix factors. Because of how `US` and `VT` are ordered, the first portions of `US` and `VT` retain the most information. So, to keep the most relevant parts, keep the first columns of `US` and first rows of `VT`. Below illustrate why this is called a dimensionality reduction method.\n",
    "\n",
    "In the following, we keep 500 columns of `US` and 500 rows of `VT` out of 1288."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct Xhat with less information: i.e. dimensionality is reduced\n",
    "Xhat_500 = US[:, 0:500] @ VT[0:500, :]\n",
    "# inverse transforms Xhat to remove standardization\n",
    "Xhat_500_orig = scaler.inverse_transform(Xhat_500)\n",
    "# draw recovered image\n",
    "draw_img(Xhat_500_orig[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using even smaller number degrades the reconstruction; however, still the reconstructed image captures the \"gist\" of the original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct Xhat with less information: i.e. dimensionality is reduced\n",
    "Xhat_100 = US[:, 0:100] @ VT[0:100, :]\n",
    "# inverse transforms Xhat to remove standardization\n",
    "Xhat_100_orig = scaler.inverse_transform(Xhat_100)\n",
    "# draw recovered image\n",
    "draw_img(Xhat_100_orig[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the dimensionality reduction and inverse transform easier, write a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduce(US_, VT_, dim=100):\n",
    "    \n",
    "    Xhat_ = US_[:, 0:dim] @ VT_[0:dim, :]\n",
    "    \n",
    "    return scaler.inverse_transform(Xhat_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the increasing the rows and columns of matrix factors used increases fidelity of reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_vec = [50, 100, 200, 400, 800]\n",
    "\n",
    "plt.figure(figsize=(1.8 * len(dim_vec), 2.4))\n",
    "\n",
    "for i, d in enumerate(dim_vec):\n",
    "    plt.subplot(1, len(dim_vec), i + 1)\n",
    "    draw_img(dim_reduce(US, VT, d)[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factors and \"Eigenfaces\"\n",
    "\n",
    "What are in these matrix factors `US` and `VT`?\n",
    "\n",
    "`VT` contains the set of \"basis\" vectors. In this setting rows of `VT` are called eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row of VT is an \"eigenface\"\n",
    "draw_img(VT[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting more eigenfaces show how the information in each eigenfaces are highlighting different components of photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_faces = 10\n",
    "# each row of VT is an \"eigenface\"\n",
    "plt.figure(figsize=(1.8 * 5, 2.4 * 2))\n",
    "\n",
    "for i in range(0, 10):\n",
    "    one_face = VT[i]\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    draw_img(one_face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each face is a linear combination of eigenfaces\n",
    "\n",
    "Reconstructing a face can be thought of as combining these eigenfaces according to some row of `US` (coefficients). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each face is a linear combination of eigenfaces VT\n",
    "\n",
    "face_num = 3 # which face to reconstruct?\n",
    "dim = 300    # higher dim is more accurate fit\n",
    "draw_img(scaler.inverse_transform(US[face_num, 0:dim] @ VT[:dim,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 3: Nonnegative Matrix Factorization\n",
    "\n",
    "NMF is a matrix factorization method that require nonnegative data matrix. Images are represented as light intensities between 0 and 255: i.e. nonnegative numbers.\n",
    "\n",
    "NMF decomposes `X` into `W` and `H` such that $X \\approx WH$. NMF is slower than SVD. So, we only choose a very small number of basis here: 200. Obtain `W` and `H`. Use [`sklearn.decomposition.NMF`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html).\n",
    "\n",
    "*Warning*: This process will take a few minutes to complete and will not converge to the optimal solution. After passing the test, you are encouraged to play around with the number of components and increasing the max_iter parameter and comparing the results.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=200, init='nndsvd', random_state=0)\n",
    "W = ...\n",
    "H = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f00ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix factor H\n",
    "\n",
    "NMF matrix factor `H` contain the set of basis faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_img(H[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following shows that the set of basis vectors are very different than what SVD chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_faces = 20\n",
    "plt.figure(figsize=(1.8 * 5, 2.4 * 4))\n",
    "\n",
    "for i in range(0, num_faces):\n",
    "    one_face = VT[i]\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    draw_img(H[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, each face is still a linear combination of matrix `H`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_img(W[30]@H) # using 200 NMF basis vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_img(dim_reduce(US, VT, 200)[30]) # using 200 SVD basis vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_img(X[30]) # original image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b38f0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36797f2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67734c81",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca959b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b47cef",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
